{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "site = 'http://www.lada-granta.net/'\n",
    "folder_names = [\n",
    "    ['0', 'Отзывы', 'f=139', 'LADA GRANTA'],\n",
    "    ['1', 'Двигатель', 'f=22', 'LADA GRANTA'],\n",
    "    ['2', 'Трансмиссия', 'f=23', 'LADA GRANTA'],\n",
    "    ['3', 'Ходовая', 'f=24', 'LADA GRANTA'],\n",
    "    ['4', 'Колеса', 'f=167', 'LADA GRANTA'],\n",
    "    ['5', 'Электрооборудование', 'f=25', 'LADA GRANTA'],\n",
    "    ['6', 'Мультимедиа', 'f=202', 'LADA GRANTA'],\n",
    "    ['7', 'Кузов', 'f=26', 'LADA GRANTA'],\n",
    "    ['8', 'Жидкости', 'f=27', 'LADA GRANTA'],\n",
    "    ['9', 'Сервис', 'f=20', 'LADA GRANTA'],\n",
    "    ['10', 'Эксплуатация', 'f=21', 'LADA GRANTA'],\n",
    "    ['11', 'Тюнинг', 'f=28', 'LADA GRANTA'],\n",
    "    ['12', 'Электрооборудование-Омыватели', 'f=184', 'LADA GRANTA'],\n",
    "    ['13', 'Электрооборудование-Зажигание', 'f=198', 'LADA GRANTA'],\n",
    "    ['14', 'Электрооборудование-Датчики', 'f=199', 'LADA GRANTA'],\n",
    "    ['15', 'Электрооборудование-Проводка', 'f=200', 'LADA GRANTA'],\n",
    "    ['16', 'Электрооборудование-Обогрев', 'f=201', 'LADA GRANTA'],\n",
    "    ['17', 'Электрооборудование-Фары', 'f=185', 'LADA GRANTA'],\n",
    "    ['18', 'Двигатель-Зажигание', 'f=195', 'LADA GRANTA'],\n",
    "    ['19', 'Двигатель-Выпуск', 'f=194', 'LADA GRANTA'],\n",
    "    ['20', 'Двигатель-Зажигание', 'f=195', 'LADA GRANTA'],\n",
    "    ['21', 'Двигатель-Охлаждение', 'f=193', 'LADA GRANTA'],\n",
    "    ['22', 'Двигатель-ГРМ', 'f=197', 'LADA GRANTA'],\n",
    "    ['24', 'Двигатель-Смазка', 'f=196', 'LADA GRANTA'],\n",
    "    ['25', 'Трансмиссия-МКПП', 'f=168', 'LADA GRANTA'],\n",
    "    ['26', 'Трансмиссия-АКПП', 'f=169', 'LADA GRANTA'],\n",
    "    ['27', 'Трансмиссия-АМТ', 'f=170', 'LADA GRANTA'],\n",
    "    ['28', 'Ходовая-Подвеска', 'f=166', 'LADA GRANTA'],\n",
    "    ['29', 'Ходовая-Тормозная', 'f=165', 'LADA GRANTA'],\n",
    "    ['30', 'Ходовая-Рулевая', 'f=164', 'LADA GRANTA'],\n",
    "    ['31', 'Кузов-Общее', 'f=176', 'LADA GRANTA'],\n",
    "    ['32', 'Кузов-Отопление', 'f=174', 'LADA GRANTA'],\n",
    "    ['33', 'Кузов-Кузов', 'f=175', 'LADA GRANTA'],\n",
    "    ['34', 'Кузов-Салон', 'f=173', 'LADA GRANTA'],\n",
    "    ['35', 'Жидкости-Топливо', 'f=182', 'LADA GRANTA'],\n",
    "    ['36', 'Жидкости-Технические', 'f=180', 'LADA GRANTA'],\n",
    "    ['37', 'Жидкости-ТрМасла', 'f=179', 'LADA GRANTA'],\n",
    "    ['38', 'Жидкости-Смазки', 'f=177', 'LADA GRANTA'],\n",
    "    ['39', 'Жидкости-МоМасла', 'f=178', 'LADA GRANTA'],\n",
    "    ['40', 'Жидкости-Присадки', 'f=181', 'LADA GRANTA'],\n",
    "    ['41', 'Жидкости-Автохимия', 'f=183', 'LADA GRANTA'],\n",
    "    ['42', 'Тюнинг-Стайлинг', 'f=142', 'LADA GRANTA'],\n",
    "    ['43', 'Тюнинг-Тюнинг', 'f=143', 'LADA GRANTA'],\n",
    "    ['44', 'Тюнинг-Противоугон', 'f=141', 'LADA GRANTA'],\n",
    "    ['45', 'Тюнинг-Автозвук', 'f=140', 'LADA GRANTA']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице раздела у нас две задачи:  \n",
    "1. Найти и сохранить все ссылки на темы\n",
    "2. Найти ссылку на следующую страницу раздела или убедиться, что это последняя страница раздела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_themes(site, folder):\n",
    "    \n",
    "    site_address = site + 'forumdisplay.php?' + folder\n",
    "    themes = []\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "    \n",
    "        resp = urlopen(site_address) # скачиваем файл\n",
    "        html = resp.read().decode('utf-8') # считываем содержимое\n",
    "        soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    \n",
    "        flag = False\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.has_attr('href') and link.has_attr('id'):\n",
    "                if re.search('thread_title_', str(link.get('id'))):\n",
    "                    s = link.get('href')\n",
    "                    s = site + 'showthread.php?' + re.search('t=[0-9]+', s)[0]\n",
    "                    themes.append([link.get_text(), s])\n",
    "            if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "                if link.get('rel')[0] == 'next':\n",
    "                    flag = True\n",
    "                    s = link.get('href')\n",
    "                    site_address = site + 'forumdisplay.php?' + re.search(folder + '[\\S]+', s)[0]\n",
    "    return themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице темы у нас три задачи:  \n",
    "1. Понять, что являеся шапкой темы (это сообщение #1), прочитать ее только один раз - НЕ СДЕЛАНО\n",
    "2. Прочитать и сохранить все сообщения (кроме шапки) на странице темы\n",
    "3. Найти ссылку на следующую страницу темы или убедиться, что это последняя страница темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(site, themes):\n",
    "\n",
    "    messages = []\n",
    "    for theme in tqdm(themes):\n",
    "        \n",
    "        print(theme[0])\n",
    "        theme_address = theme[1]\n",
    "        thread = re.search('t=[0-9]+', theme_address)[0]\n",
    "        flag = True\n",
    "        theme_messages = []\n",
    "        post_data = {}\n",
    "        \n",
    "        while flag:\n",
    "            resp = urlopen(theme_address) # скачиваем файл\n",
    "            html = resp.read().decode('utf-8', errors='ignore') # считываем содержимое\n",
    "            soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "            #Собираем некоторые метаданные сообщений на текущей странице\n",
    "            tables = soup.find_all('table')\n",
    "            for next_table in tables:\n",
    "                if next_table.has_attr('id') and re.search('post[0-9]+', next_table['id']):\n",
    "                    post_column = next_table.find('td')\n",
    "                    post_date = post_column.get_text().strip()\n",
    "                    post_data[re.sub('post', '', next_table['id'])] = [post_date]\n",
    "            #Собираем сами сообщения\n",
    "            divs = soup.find_all('div')\n",
    "            for div in divs:\n",
    "                if div.has_attr('id') and re.search('(postmenu_)([0-9]+)(_menu)', div['id']):\n",
    "                    continue\n",
    "                if div.has_attr('id') and re.search('postmenu_', div['id']):\n",
    "                    author = div.find('a')\n",
    "                    if author != None:\n",
    "                        author_id = re.search('u=[0-9]+', author['href'])[0]\n",
    "                        author_nickname = author.get_text()\n",
    "                    else:\n",
    "                        author_id = div.get_text().strip()\n",
    "                        author_nickname = 'Guest'\n",
    "                    post_data[re.sub('postmenu_', '', div['id'])].append([author_id, author_nickname])\n",
    "                if div.has_attr('id') and re.search('post_message_', div['id']):\n",
    "                    message_id = re.sub('post_message_', '', div['id'])\n",
    "                    if message_id in post_data:\n",
    "                        post_date = post_data[message_id][0]\n",
    "                        author = post_data[message_id][1][1]\n",
    "                    else:\n",
    "                        post_date = ''\n",
    "                        author = ''\n",
    "                    for item in div.children:\n",
    "                        if item.name == 'div':\n",
    "                            item.clear()\n",
    "                    s = re.sub('[\\']+', '`', div.get_text())\n",
    "                    s = '\\'' + re.sub('[\\s]+', ' ', s).strip() + '\\''\n",
    "                    if len(s) > 2:\n",
    "                        theme_messages.append([post_date, author, s])\n",
    "            # В отдельном цикле ищем ссылку на следующую страницу темы (это 'a' с атрибутом 'rel', равным 'next')\n",
    "            # Если ссылка найдена, \n",
    "            flag = False \n",
    "            for link in soup.find_all('a'):\n",
    "                if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "                    if link.get('rel')[0] == 'next':\n",
    "                        flag = True\n",
    "                        s = link.get('href')\n",
    "                        theme_address = site + 'showthread.php?' + re.search(thread + '[\\S]+', s)[0]\n",
    "        messages.append(['\\''+ theme[0] + '\\'', theme_messages])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_messages(messages, folder_name):\n",
    "    f_name = os.path.join(folder_name[3], folder_name[3] + '_' + folder_name[0] + '_' + folder_name[1] + '.csv')\n",
    "    with open(f_name, 'w', encoding='utf-8') as ouf:\n",
    "        ouf.write('Code,Folder,Theme,Date,Time,Author,Message\\n')\n",
    "        for message in messages:\n",
    "            header = folder_name[:2] + [message[0]]\n",
    "            for item in message[1]:\n",
    "                ouf.write(','.join(header + item))\n",
    "                ouf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(site, folder_names):\n",
    "    for folder_name in folder_names:\n",
    "        if len(folder_name[2]) > 0:\n",
    "            folder = folder_name[2]\n",
    "            current_themes = collect_themes(site, folder)\n",
    "            current_messages = collect_messages(site, current_themes)\n",
    "            save_messages(current_messages, folder_name)\n",
    "    print('Information collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraper(site, folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#mess = pd.read_csv('./LADA GRANTA/LADA GRANTA_5_Электрооборудование.csv', quotechar=\"'\")\n",
    "#mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
