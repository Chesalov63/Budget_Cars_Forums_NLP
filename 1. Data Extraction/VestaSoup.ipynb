{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "site = 'http://www.lada-vesta.net/'\n",
    "folder_names = [\n",
    "    ['0', 'Отзывы', 'f=25', 'LADA VESTA'],\n",
    "    ['1', 'Двигатель', 'f=14', 'LADA VESTA'],\n",
    "    ['2', 'Трансмиссия', 'f=15', 'LADA VESTA'],\n",
    "    ['3', 'Ходовая', 'f=16', 'LADA VESTA'],\n",
    "    ['4', 'Колеса', '', 'LADA VESTA'],\n",
    "    ['5', 'Электрооборудование', 'f=17', 'LADA VESTA'],\n",
    "    ['6', 'Мультимедиа', '', 'LADA VESTA'],\n",
    "    ['7', 'Кузов', 'f=18', 'LADA VESTA'],\n",
    "    ['8', 'Жидкости', 'f=19', 'LADA VESTA'],\n",
    "    ['9', 'Сервис', 'f=42', 'LADA VESTA'],\n",
    "    ['10', 'Эксплуатация', 'f=23', 'LADA VESTA'],\n",
    "    ['11', 'Тюнинг', 'f=24', 'LADA VESTA']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице раздела у нас две задачи:  \n",
    "1. Найти и сохранить все ссылки на темы\n",
    "2. Найти ссылку на следующую страницу раздела или убедиться, что это последняя страница раздела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_themes(site, folder):\n",
    "    \n",
    "    site_address = site + 'forumdisplay.php?' + folder\n",
    "    themes = []\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "    \n",
    "        resp = urlopen(site_address) # скачиваем файл\n",
    "        html = resp.read().decode('utf-8') # считываем содержимое\n",
    "        soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    \n",
    "        flag = False\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.has_attr('href') and link.has_attr('id'):\n",
    "                if re.search('thread_title_', str(link.get('id'))):\n",
    "                    s = link.get('href')\n",
    "                    s = site + 'showthread.php?' + re.search('t=[0-9]+', s)[0]\n",
    "                    themes.append([link.get_text(), s])\n",
    "            if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "                if link.get('rel')[0] == 'next':\n",
    "                    flag = True\n",
    "                    s = link.get('href')\n",
    "                    site_address = site + 'forumdisplay.php?' + re.search(folder + '[\\S]+', s)[0]\n",
    "    return themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице темы у нас три задачи:  \n",
    "1. Понять, что являеся шапкой темы (это сообщение #1), прочитать ее только один раз - НЕ СДЕЛАНО\n",
    "2. Прочитать и сохранить все сообщения (кроме шапки) на странице темы\n",
    "3. Найти ссылку на следующую страницу темы или убедиться, что это последняя страница темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(site, themes):\n",
    "\n",
    "    messages = []\n",
    "    for theme in tqdm(themes):\n",
    "        \n",
    "        print(theme[0])\n",
    "        theme_address = theme[1]\n",
    "        thread = re.search('t=[0-9]+', theme_address)[0]\n",
    "        flag = True\n",
    "        theme_messages = []\n",
    "        post_data = {}\n",
    "        \n",
    "        while flag:\n",
    "            resp = urlopen(theme_address) # скачиваем файл\n",
    "            html = resp.read().decode('utf-8', errors='ignore') # считываем содержимое\n",
    "            soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "            #Собираем некоторые метаданные сообщений на текущей странице\n",
    "            tables = soup.find_all('table')\n",
    "            for next_table in tables:\n",
    "                if next_table.has_attr('id') and re.search('post[0-9]+', next_table['id']):\n",
    "                    post_column = next_table.find('td')\n",
    "                    post_date = post_column.get_text().strip()\n",
    "                    post_data[re.sub('post', '', next_table['id'])] = [post_date]\n",
    "            #Собираем сами сообщения\n",
    "            divs = soup.find_all('div')\n",
    "            for div in divs:\n",
    "                if div.has_attr('id') and re.search('(postmenu_)([0-9]+)(_menu)', div['id']):\n",
    "                    continue\n",
    "                if div.has_attr('id') and re.search('postmenu_', div['id']):\n",
    "                    author = div.find('a')\n",
    "                    if author != None:\n",
    "                        author_id = re.search('u=[0-9]+', author['href'])[0]\n",
    "                        author_nickname = author.get_text()\n",
    "                    else:\n",
    "                        author_id = div.get_text().strip()\n",
    "                        author_nickname = 'Guest'\n",
    "                    post_data[re.sub('postmenu_', '', div['id'])].append([author_id, author_nickname])\n",
    "                if div.has_attr('id') and re.search('post_message_', div['id']):\n",
    "                    message_id = re.sub('post_message_', '', div['id'])\n",
    "                    if message_id in post_data:\n",
    "                        post_date = post_data[message_id][0]\n",
    "                        author = post_data[message_id][1][1]\n",
    "                    else:\n",
    "                        post_date = ''\n",
    "                        author = ''\n",
    "                    for item in div.children:\n",
    "                        if item.name == 'div':\n",
    "                            item.clear()\n",
    "                    s = re.sub('[\\']+', '`', div.get_text())\n",
    "                    s = '\\'' + re.sub('[\\s]+', ' ', s).strip() + '\\''\n",
    "                    if len(s) > 2:\n",
    "                        theme_messages.append([post_date, author, s])\n",
    "            # В отдельном цикле ищем ссылку на следующую страницу темы (это 'a' с атрибутом 'rel', равным 'next')\n",
    "            # Если ссылка найдена, \n",
    "            flag = False \n",
    "            for link in soup.find_all('a'):\n",
    "                if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "                    if link.get('rel')[0] == 'next':\n",
    "                        flag = True\n",
    "                        s = link.get('href')\n",
    "                        theme_address = site + 'showthread.php?' + re.search(thread + '[\\S]+', s)[0]\n",
    "        messages.append(['\\''+ theme[0] + '\\'', theme_messages])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_messages(messages, folder_name):\n",
    "    f_name = os.path.join(folder_name[3], folder_name[3] + '_' + folder_name[0] + '_' + folder_name[1] + '.csv')\n",
    "    with open(f_name, 'w', encoding='utf-8') as ouf:\n",
    "        ouf.write('Code,Folder,Theme,Date,Time,Author,Message\\n')\n",
    "        for message in messages:\n",
    "            header = folder_name[:2] + [message[0]]\n",
    "            for item in message[1]:\n",
    "                ouf.write(','.join(header + item))\n",
    "                ouf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(site, folder_names):\n",
    "    for folder_name in folder_names:\n",
    "        if len(folder_name[2]) > 0:\n",
    "            folder = folder_name[2]\n",
    "            current_themes = collect_themes(site, folder)\n",
    "            current_messages = collect_messages(site, current_themes)\n",
    "            save_messages(current_messages, folder_name)\n",
    "    print('Information collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ipytelegram extension is already loaded. To reload it, use:\n",
      "  %reload_ext ipytelegram\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipytelegram\n",
    "%reload_ext ipytelegram\n",
    "import telepot\n",
    "bot = telepot.Bot('1301715666:AAGBzLlVDZI7KzGZ_DNyukjauVeTt0QpO-A')\n",
    "response = bot.getUpdates()\n",
    "%telegram_setup 1301715666:AAGBzLlVDZI7KzGZ_DNyukjauVeTt0QpO-A 1305740495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%telegram_send Next message\n",
    "scraper(site, folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mess = pd.read_csv('./LADA VESTA/LADA VESTA_10_Эксплуатация.csv', quotechar=\"'\")\n",
    "mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = [['7', 'Кузов', 'f=18', 'LADA VESTA']]\n",
    "folder = folder_names[0][2]\n",
    "current_themes = collect_themes(site, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = []\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    \n",
    "    resp = urlopen(site_address) # скачиваем файл\n",
    "    html = resp.read().decode('utf-8') # считываем содержимое\n",
    "    soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    \n",
    "    flag = False\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.has_attr('href') and link.has_attr('id'):\n",
    "            if re.search('thread_title_', str(link.get('id'))):\n",
    "                s = link.get('href')\n",
    "                s = site + 'showthread.php?' + re.search('t=[0-9]+', s)[0]\n",
    "                themes.append([link.get_text(), s])\n",
    "        if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "            if link.get('rel')[0] == 'next':\n",
    "                flag = True\n",
    "                s = link.get('href')\n",
    "                site_address = site + 'forumdisplay.php?' + re.search(folder + '[\\S]+', s)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = [['Механика, робот или автомат?',\n",
    "  'http://www.lada-vesta.net/showthread.php?t=47']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "for theme in tqdm(themes):\n",
    "    theme_address = theme[1]\n",
    "    thread = re.search('t=[0-9]+', theme_address)[0]\n",
    "    flag = True\n",
    "    theme_messages = []\n",
    "    post_data = {}\n",
    "    while flag:\n",
    "        resp = urlopen(theme_address) # скачиваем файл\n",
    "        html = resp.read().decode('utf-8', errors='ignore') # считываем содержимое\n",
    "        soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "        #Собираем некоторые метаданные сообщений на текущей странице\n",
    "        tables = soup.find_all('table')\n",
    "        for next_table in tables:\n",
    "            if next_table.has_attr('id') and re.search('post[0-9]+', next_table['id']):\n",
    "                post_column = next_table.find('td')\n",
    "                post_date = post_column.get_text().strip()\n",
    "                post_data[re.sub('post', '', next_table['id'])] = [post_date]\n",
    "        #Собираем сами сообщения\n",
    "        divs = soup.find_all('div')\n",
    "        for div in divs:\n",
    "            if div.has_attr('id') and re.search('(postmenu_)([0-9]+)(_menu)', div['id']):\n",
    "                continue\n",
    "            if div.has_attr('id') and re.search('postmenu_', div['id']):\n",
    "                author = div.find('a')\n",
    "                if author != None:\n",
    "                    author_id = re.search('u=[0-9]+', author['href'])[0]\n",
    "                    author_nickname = author.get_text()\n",
    "                else:\n",
    "                    author_id = div.get_text().strip()\n",
    "                    author_nickname = 'Guest'\n",
    "                post_data[re.sub('postmenu_', '', div['id'])].append([author_id, author_nickname])\n",
    "                print(re.sub('postmenu_', '', div['id']), post_data[re.sub('postmenu_', '', div['id'])])\n",
    "            if div.has_attr('id') and re.search('post_message_', div['id']):\n",
    "                message_id = re.sub('post_message_', '', div['id'])\n",
    "                if message_id in post_data:\n",
    "                    post_date = post_data[message_id][0]\n",
    "                    author = post_data[message_id][1][1]\n",
    "                else:\n",
    "                    post_date = ''\n",
    "                    author = ''\n",
    "                for item in div.children:\n",
    "                    if item.name == 'div':\n",
    "                        item.clear()\n",
    "                s = re.sub('[\\']+', '`', div.get_text())\n",
    "                s = '\\'' + re.sub('[\\s]+', ' ', s) + '\\''\n",
    "                if len(s) > 0:\n",
    "                    theme_messages.append([post_date, author, s])\n",
    "        # В отдельном цикле ищем ссылку на следующую страницу темы (это 'a' с атрибутом 'rel', равным 'next')\n",
    "        # Если ссылка найдена, \n",
    "        flag = False \n",
    "        for link in soup.find_all('a'):\n",
    "            if not flag and link.has_attr('href') and link.has_attr('rel'):\n",
    "                if link.get('rel')[0] == 'next':\n",
    "                    flag = True\n",
    "                    s = link.get('href')\n",
    "                    theme_address = site + 'showthread.php?' + re.search(thread + '[\\S]+', s)[0]\n",
    "    messages.append(['\\''+ theme[0] + '\\'', theme_messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = os.path.join(folder_name[3], folder_name[3] + '_' + folder_name[0] + '_' + folder_name[1] + '.csv')\n",
    "with open(f_name, 'w', encoding='utf-8') as ouf:\n",
    "    ouf.write('Code,Folder,Theme,Date,Author,Message\\n')\n",
    "    for message in messages:\n",
    "        header = folder_name[:2] + [message[0]]\n",
    "        for item in message[1]:\n",
    "            ouf.write(','.join(header + item))\n",
    "            ouf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LADA VESTA/LADA VESTA_0_Отзывы.csv'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = ['0', 'Отзывы', 'f=25', 'LADA VESTA']\n",
    "f_name = folder_name[3] + '/' + folder_name[3] + '_' + folder_name[0] + '_' + folder_name[1] + '.csv'\n",
    "f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''messages = []\n",
    "theme_address = 'http://www.lada-vesta.net/showthread.php?t=9571'\n",
    "resp = urlopen(theme_address) # скачиваем файл\n",
    "html = resp.read().decode('utf-8', errors='ignore') # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "divs = soup.find_all('div')\n",
    "for div in divs:\n",
    "    if div.has_attr('id'):\n",
    "        if re.search('post_message_', div['id']):\n",
    "            for item in div.children:\n",
    "                if item.name != 'div':\n",
    "                    s = str(item).strip()\n",
    "                    if len(s) > 0:\n",
    "                        messages.append([s])\n",
    "print(messages)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
