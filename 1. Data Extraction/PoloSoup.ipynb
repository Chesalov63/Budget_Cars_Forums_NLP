{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "site = 'http://www.polosedan-club.com/'\n",
    "folder_names = [\n",
    "    ['0', 'Отзывы', 'Отзывы-владельцев-о-Поло-седан-polo-sedan.13', 'FW POLO'],\n",
    "    ['1', 'Двигатель', 'Двигатель-и-его-системы.18', 'FW POLO'],\n",
    "    ['2', 'Трансмиссия', 'Сцепление-и-коробка-передач.19', 'FW POLO'],\n",
    "    ['3', 'Ходовая', 'Ходовая-и-подвеска.20', 'FW POLO'],\n",
    "    ['4', 'Колеса', 'Шины-и-колесные-диски.32', 'FW POLO'],\n",
    "    ['5', 'Электрооборудование', 'Электрооборудование.21', 'FW POLO'],\n",
    "    ['6', 'Мультимедиа', 'Аудио-Видео-системы-автомобиля.43', 'FW POLO'],\n",
    "    ['7', 'Кузов', 'Кузов-и-система-отопления.22', 'FW POLO'],\n",
    "    ['8', 'Жидкости', 'Топливо-и-эксплуатационные-жидкости.23', 'FW POLO'],\n",
    "    ['9', 'Сервис', 'Гарантийное-и-сервисное-обслуживание.16', 'FW POLO'],\n",
    "    ['10', 'Эксплуатация', 'Общие-вопросы-эксплуатации.17', 'FW POLO'],\n",
    "    ['11', 'Тюнинг', 'Стайлинг-Тюнинг-Доп-оборудование-Защита.24', 'FW POLO'],\n",
    "    ['12', 'Эксплуатация-Ремонт', 'Ремонт-и-доработки-своими-силами.48', 'FW POLO'],\n",
    "    ['13', 'Эксплуатация-Вопросы', 'Вопросы-возникшие-при-эксплуатации-автомобиля.47', 'FW POLO'],\n",
    "    ['14', 'Проблемы-Заводской брак', 'Проблемы-заводской-брак-и-тд.44', 'FW POLO']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице раздела у нас две задачи:  \n",
    "1. Найти и сохранить все ссылки на темы\n",
    "2. Найти ссылку на следующую страницу раздела или убедиться, что это последняя страница раздела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_themes(site, folder):\n",
    "    \n",
    "    site_address = site + 'forums/' + quote_plus(folder) + '/'\n",
    "    themes = []\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "    \n",
    "        resp = urlopen(site_address) # скачиваем файл\n",
    "        html = resp.read().decode('utf-8') # считываем содержимое\n",
    "        soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    \n",
    "        flag = False\n",
    "        for li in soup.find_all('li'):\n",
    "            if li.find('h3'):\n",
    "                h3 = li.find('h3')\n",
    "                if h3.find('a'):\n",
    "                    link = h3.find('a')\n",
    "                    s = link.get('href')\n",
    "                    theme = site + s\n",
    "                    themes.append([link.get_text(), theme])\n",
    "        \n",
    "        for link in soup.find_all('a'):\n",
    "            if link.has_attr('href'):\n",
    "                if link.has_attr('class') and link.get('class') == ['text']:\n",
    "                    if re.search('Вперёд', link.get_text()):\n",
    "                        flag = True\n",
    "                        s = link.get('href')\n",
    "                        site_address = site + s \n",
    "                        break\n",
    "    return themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице темы у нас три задачи:  \n",
    "1. Понять, что являеся шапкой темы (это сообщение #1), прочитать ее только один раз - НЕ СДЕЛАНО\n",
    "2. Прочитать и сохранить все сообщения (кроме шапки) на странице темы\n",
    "3. Найти ссылку на следующую страницу темы или убедиться, что это последняя страница темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(site, themes):\n",
    "\n",
    "    messages = []\n",
    "    for theme in tqdm(themes):\n",
    "        \n",
    "        print(theme[0])\n",
    "        theme_address = theme[1]\n",
    "        flag = True\n",
    "        theme_messages = []\n",
    "        post_data = {}\n",
    "\n",
    "        while flag:\n",
    "            try:\n",
    "                resp = urlopen(theme_address) # скачиваем файл\n",
    "            except:\n",
    "                break\n",
    "            html = resp.read().decode('utf-8', errors='ignore') # считываем содержимое\n",
    "            soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "            #Собираем сами сообщения\n",
    "            lis = soup.find_all('li')\n",
    "            for li in lis:\n",
    "                if li.has_attr('id') and re.search('post-', li['id']):\n",
    "                    author = li['data-author']\n",
    "                    for div in li.find_all('div'):\n",
    "                        if div.has_attr('class') and div['class'] == ['messageContent']:\n",
    "                            blockquote = div.find('article').find('blockquote')\n",
    "                            if blockquote.find('div'):\n",
    "                                quote = blockquote.find('div')\n",
    "                                quote.clear()\n",
    "                            s = blockquote.get_text().strip()\n",
    "                            s = re.sub('[\\']+', '`', s)\n",
    "                            s = '\\'' + re.sub('[\\s]+', ' ', s).strip() + '\\''\n",
    "                            post_date = ''\n",
    "                            more_divs = div.find_next_siblings('div')\n",
    "                            for next_div in more_divs:\n",
    "                                for span in next_div.find_all('span'):\n",
    "                                    if re.search('[0-9]+ [а-я]+ [0-9]{4}', span.get_text().strip()):\n",
    "                                        post_date = re.search('[0-9]+ [а-я]+ [0-9]{4}', span.get_text().strip())[0]\n",
    "                                        break\n",
    "                            if len(s) > 2:\n",
    "                                theme_messages.append([post_date, author, s])\n",
    "            # В отдельном цикле ищем ссылку на следующую страницу темы (это 'a' с атрибутом 'rel', равным 'next')\n",
    "            # Если ссылка найдена, \n",
    "            flag = False \n",
    "            for link in soup.find_all('a'):\n",
    "                if link.has_attr('href'):\n",
    "                    if link.has_attr('class') and link.get('class') == ['text']:\n",
    "                        if re.search('Вперёд', link.get_text()):\n",
    "                            flag = True\n",
    "                            s = link.get('href')\n",
    "                            theme_address = site + s\n",
    "                            break\n",
    "        if len(theme_messages) > 0:\n",
    "            messages.append(['\\''+ theme[0] + '\\'', theme_messages])\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_messages(messages, folder_name):\n",
    "    f_name = os.path.join(folder_name[3], folder_name[3] + '_' + folder_name[0] + '_' + folder_name[1] + '.csv')\n",
    "    with open(f_name, 'w', encoding='utf-8') as ouf:\n",
    "        ouf.write('Code,Folder,Theme,Date,Author,Message\\n')\n",
    "        for message in messages:\n",
    "            header = folder_name[:2] + [message[0]]\n",
    "            for item in message[1]:\n",
    "                ouf.write(','.join(header + item))\n",
    "                ouf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(site, folder_names):\n",
    "    for folder_name in folder_names:\n",
    "        if len(folder_name[2]) > 0:\n",
    "            folder = folder_name[2]\n",
    "            current_themes = collect_themes(site, folder)\n",
    "            current_messages = collect_messages(site, current_themes)\n",
    "            save_messages(current_messages, folder_name)\n",
    "    print('Information collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraper(site, folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#mess = pd.read_csv('./FW POLO/FW POLO_5_Электрооборудование.csv', quotechar=\"'\")\n",
    "#mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
